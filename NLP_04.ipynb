{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_04.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0TH30QECWWw"
      },
      "source": [
        "Can you think of a few applications for a sequence-to-sequence RNN? What about a sequence-to-vector RNN? And a vector-to-sequence RNN?\n",
        "Ans: \n",
        "In Sequence to Sequence Learning, RNN is trained to map an input sequence to an output sequence which is not necessarily of the same length.\n",
        "Applications are speech recognition, machine translation, image captioning and question answering.\n",
        "\n",
        "Why do people use encoder–decoder RNNs rather than plain sequence-to-sequence RNNs for automatic translation?\n",
        "Ans: \n",
        "Encoder-Decoder Recurrent Neural Network Models for Neural Machine Translation\n",
        "by Jason Brownlee on January 1, 2018 in Deep Learning for Natural Language Processing\n",
        "Tweet  Share\n",
        "Last Updated on August 7, 2019\n",
        "\n",
        "The encoder-decoder architecture for recurrent neural networks is the standard neural machine translation method that rivals and in some cases outperforms classical statistical machine translation methods.\n",
        "\n",
        "This architecture is very new, having only been pioneered in 2014, although, has been adopted as the core technology inside Google’s translate service.\n",
        "\n",
        "In this post, you will discover the two seminal examples of the encoder-decoder model for neural machine translation.\n",
        "\n",
        "After reading this post, you will know:\n",
        "\n",
        "The encoder-decoder recurrent neural network architecture is the core technology inside Google’s translate service.\n",
        "The so-called “Sutskever model” for direct end-to-end machine translation.\n",
        "The so-called “Cho model” that extends the architecture with GRU units and an attention mechanism.\n",
        "\n",
        "How could you combine a convolutional neural network with an RNN to classify videos?\n",
        "Ans: \n",
        "That was my reaction when I first came across the idea of combining CNNs (convolutional neural nets) and RNNs (recurrent neural nets).  After all they’re optimized for completely different problem types.\n",
        "\n",
        "CNNs are good with hierarchical or spatial data and extracting unlabeled features. Those could be images or written characters.  CNNs take fixed size inputs and generate fixed size outputs.\n",
        "RNNs are good at temporal or otherwise sequential data. Could be letters or words in a body of text, stock market data, or speech recognition.  RNNs can input and output arbitrary lengths of data.  LSTMs are a variant of RNNs that allow for controlling how much of prior training data should be remembered, or more appropriately forgotten.\n",
        "\n",
        "What are the advantages of building an RNN using dynamic_rnn() rather than static_rnn()?\n",
        "Ans: \n",
        "Static\n",
        "\n",
        "Internally, tf.nn.rnn creates an unrolled graph for a fixed RNN length. That means, if you call tf.nn.rnn with inputs having 200 time steps you are creating a static graph with 200 RNN steps. First, graph creation is slow. Second, you’re unable to pass in longer sequences (> 200) than you’ve originally specified.\n",
        "\n",
        "Dynamic\n",
        "\n",
        "tf.nn.dynamic_rnn solves this. It uses a tf.While loop to dynamically construct the graph when it is executed. That means graph creation is faster and you can feed batches of variable size.\n",
        "\n",
        "\n",
        "How can you deal with variable-length input sequences? What about variable-length output sequences?\n",
        "Ans: \n",
        "Deep learning libraries assume a vectorized representation of your data.\n",
        "\n",
        "In the case of variable length sequence prediction problems, this requires that your data be transformed such that each sequence has the same length.\n",
        "\n",
        "This vectorization allows code to efficiently perform the matrix operations in batch for your chosen deep learning algorithms.\n",
        "\n",
        "In this tutorial, you will discover techniques that you can use to prepare your variable length sequence data for sequence prediction problems in Python with Keras.\n",
        "\n",
        "\n",
        "\n",
        "What is a common way to distribute training and execution of a deep RNN across multiple GPUs?\n",
        "Ans: \n",
        "Up to now we have mostly looked at feedforward neural networks, where the activations flow only in one direction, from the input layer to the output layer. A recurrent neural network looks very much like a feedforward neural network, except it also has connections pointing backward. Let’s look at the simplest possible RNN, composed of just one neuron receiving inputs, producing an output, and sending that output back to itself, as shown in Figure 4-1 (left). At each time step t (also called a frame), this recurrent neuron receives the inputs x(t) as well as its own output from the previous time step, y(t–1). We can represent this tiny network against the time axis, as shown in Figure 4-1 (right). This is called unrolling the network through time.\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}